Apache Airflow is a workflow management platform. 
This makes it easier to build data pipelines, monitor them, and perform ETL operations. 

Airflow pipelines are configuration as code (Python), allowing for dynamic pipeline generation. 
They are lean and explicit.
Airflow has a modular architecture and uses a message queue to orchestrate an arbitrary number of workers. 

But you can run it on your laptop.

This Docker container ships Airflow based on Anaconda (miniconda3) to make 
running machine learning pipelines and data science tasks seamless. 

Anaconda is an open source Python distribution for data science, machine learning, 
and large-scale data processing tasks with over 1,400 packages. 

Running Airflow on the Anaconda environment provides users with a simple and robust tool for building 
complex data pipelines for machine learning and data science tasks. 

Latest tag builds Airflow 1.10.12 with Miniconda 3.
